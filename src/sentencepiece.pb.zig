// Code generated by protoc-gen-zig
///! package sentencepiece
const std = @import("std");

const protobuf = @import("protobuf");
const fd = protobuf.fd;

/// TrainerSpec encodes a various parameters for SentencePiece training.
/// Next id: 55
pub const TrainerSpec = struct {
    input: std.ArrayListUnmanaged([]const u8) = .empty,
    input_format: ?[]const u8 = null,
    model_prefix: ?[]const u8 = null,
    model_type: ?TrainerSpec.ModelType = .UNIGRAM,
    vocab_size: ?i32 = 8000,
    accept_language: std.ArrayListUnmanaged([]const u8) = .empty,
    self_test_sample_size: ?i32 = 0,
    enable_differential_privacy: ?bool = false,
    differential_privacy_noise_level: ?f32 = 0,
    differential_privacy_clipping_threshold: ?u64 = 0,
    character_coverage: ?f32 = 0.9995,
    input_sentence_size: ?u64 = 0,
    shuffle_input_sentence: ?bool = true,
    mining_sentence_size: ?i32 = null,
    training_sentence_size: ?i32 = null,
    seed_sentencepiece_size: ?i32 = 1000000,
    shrinking_factor: ?f32 = 0.75,
    max_sentence_length: ?i32 = 4192,
    num_threads: ?i32 = 16,
    num_sub_iterations: ?i32 = 2,
    max_sentencepiece_length: ?i32 = 16,
    split_by_unicode_script: ?bool = true,
    split_by_number: ?bool = true,
    split_by_whitespace: ?bool = true,
    treat_whitespace_as_suffix: ?bool = false,
    allow_whitespace_only_pieces: ?bool = false,
    split_digits: ?bool = false,
    pretokenization_delimiter: ?[]const u8 = &.{},
    control_symbols: std.ArrayListUnmanaged([]const u8) = .empty,
    user_defined_symbols: std.ArrayListUnmanaged([]const u8) = .empty,
    required_chars: ?[]const u8 = null,
    byte_fallback: ?bool = false,
    vocabulary_output_piece_score: ?bool = true,
    hard_vocab_limit: ?bool = true,
    use_all_vocab: ?bool = false,
    unk_id: ?i32 = 0,
    bos_id: ?i32 = 1,
    eos_id: ?i32 = 2,
    pad_id: ?i32 = -1,
    unk_piece: ?[]const u8 = "<unk>",
    bos_piece: ?[]const u8 = "<s>",
    eos_piece: ?[]const u8 = "</s>",
    pad_piece: ?[]const u8 = "<pad>",
    unk_surface: ?[]const u8 = " \xe2\x81\x87 ",
    train_extremely_large_corpus: ?bool = false,
    seed_sentencepieces_file: ?[]const u8 = &.{},

    pub const _desc_table = .{
        .input = fd(1, .{ .repeated = .{ .scalar = .string } }),
        .input_format = fd(7, .{ .scalar = .string }),
        .model_prefix = fd(2, .{ .scalar = .string }),
        .model_type = fd(3, .@"enum"),
        .vocab_size = fd(4, .{ .scalar = .int32 }),
        .accept_language = fd(5, .{ .repeated = .{ .scalar = .string } }),
        .self_test_sample_size = fd(6, .{ .scalar = .int32 }),
        .enable_differential_privacy = fd(50, .{ .scalar = .bool }),
        .differential_privacy_noise_level = fd(51, .{ .scalar = .float }),
        .differential_privacy_clipping_threshold = fd(52, .{ .scalar = .uint64 }),
        .character_coverage = fd(10, .{ .scalar = .float }),
        .input_sentence_size = fd(11, .{ .scalar = .uint64 }),
        .shuffle_input_sentence = fd(19, .{ .scalar = .bool }),
        .mining_sentence_size = fd(12, .{ .scalar = .int32 }),
        .training_sentence_size = fd(13, .{ .scalar = .int32 }),
        .seed_sentencepiece_size = fd(14, .{ .scalar = .int32 }),
        .shrinking_factor = fd(15, .{ .scalar = .float }),
        .max_sentence_length = fd(18, .{ .scalar = .int32 }),
        .num_threads = fd(16, .{ .scalar = .int32 }),
        .num_sub_iterations = fd(17, .{ .scalar = .int32 }),
        .max_sentencepiece_length = fd(20, .{ .scalar = .int32 }),
        .split_by_unicode_script = fd(21, .{ .scalar = .bool }),
        .split_by_number = fd(23, .{ .scalar = .bool }),
        .split_by_whitespace = fd(22, .{ .scalar = .bool }),
        .treat_whitespace_as_suffix = fd(24, .{ .scalar = .bool }),
        .allow_whitespace_only_pieces = fd(26, .{ .scalar = .bool }),
        .split_digits = fd(25, .{ .scalar = .bool }),
        .pretokenization_delimiter = fd(53, .{ .scalar = .string }),
        .control_symbols = fd(30, .{ .repeated = .{ .scalar = .string } }),
        .user_defined_symbols = fd(31, .{ .repeated = .{ .scalar = .string } }),
        .required_chars = fd(36, .{ .scalar = .string }),
        .byte_fallback = fd(35, .{ .scalar = .bool }),
        .vocabulary_output_piece_score = fd(32, .{ .scalar = .bool }),
        .hard_vocab_limit = fd(33, .{ .scalar = .bool }),
        .use_all_vocab = fd(34, .{ .scalar = .bool }),
        .unk_id = fd(40, .{ .scalar = .int32 }),
        .bos_id = fd(41, .{ .scalar = .int32 }),
        .eos_id = fd(42, .{ .scalar = .int32 }),
        .pad_id = fd(43, .{ .scalar = .int32 }),
        .unk_piece = fd(45, .{ .scalar = .string }),
        .bos_piece = fd(46, .{ .scalar = .string }),
        .eos_piece = fd(47, .{ .scalar = .string }),
        .pad_piece = fd(48, .{ .scalar = .string }),
        .unk_surface = fd(44, .{ .scalar = .string }),
        .train_extremely_large_corpus = fd(49, .{ .scalar = .bool }),
        .seed_sentencepieces_file = fd(54, .{ .scalar = .string }),
    };

    /// Model type. only have UNIGRAM now.
    pub const ModelType = enum(i32) {
        UNIGRAM = 1,
        BPE = 2,
        WORD = 3,
        CHAR = 4,
        _,
    };

    /// Encodes the message to the writer
    /// The allocator is used to generate submessages internally.
    /// Hence, an ArenaAllocator is a preferred choice if allocations are a bottleneck.
    pub fn encode(
        self: @This(),
        writer: *std.Io.Writer,
        allocator: std.mem.Allocator,
    ) (std.Io.Writer.Error || std.mem.Allocator.Error)!void {
        return protobuf.encode(writer, allocator, self);
    }

    /// Decodes the message from the bytes read from the reader.
    pub fn decode(
        reader: *std.Io.Reader,
        allocator: std.mem.Allocator,
    ) (protobuf.DecodingError || std.Io.Reader.Error || std.mem.Allocator.Error)!@This() {
        return protobuf.decode(@This(), reader, allocator);
    }

    /// Deinitializes and frees the memory associated with the message.
    pub fn deinit(self: *@This(), allocator: std.mem.Allocator) void {
        return protobuf.deinit(allocator, self);
    }

    /// Duplicates the message.
    pub fn dupe(self: @This(), allocator: std.mem.Allocator) std.mem.Allocator.Error!@This() {
        return protobuf.dupe(@This(), self, allocator);
    }

    /// Decodes the message from the JSON string.
    pub fn jsonDecode(
        input: []const u8,
        options: std.json.ParseOptions,
        allocator: std.mem.Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.json.decode(@This(), input, options, allocator);
    }

    /// Encodes the message to a JSON string.
    pub fn jsonEncode(
        self: @This(),
        options: std.json.Stringify.Options,
        allocator: std.mem.Allocator,
    ) ![]const u8 {
        return protobuf.json.encode(self, options, allocator);
    }

    /// This method is used by std.json
    /// internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: std.mem.Allocator,
        source: anytype,
        options: std.json.ParseOptions,
    ) !@This() {
        return protobuf.json.parse(@This(), allocator, source, options);
    }

    /// This method is used by std.json
    /// internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.json.stringify(@This(), self, jws);
    }
};

/// NormalizerSpec encodes a various parameters for string normalizaiton
pub const NormalizerSpec = struct {
    name: ?[]const u8 = null,
    precompiled_charsmap: ?[]const u8 = null,
    add_dummy_prefix: ?bool = true,
    remove_extra_whitespaces: ?bool = true,
    escape_whitespaces: ?bool = true,
    normalization_rule_tsv: ?[]const u8 = null,

    pub const _desc_table = .{
        .name = fd(1, .{ .scalar = .string }),
        .precompiled_charsmap = fd(2, .{ .scalar = .bytes }),
        .add_dummy_prefix = fd(3, .{ .scalar = .bool }),
        .remove_extra_whitespaces = fd(4, .{ .scalar = .bool }),
        .escape_whitespaces = fd(5, .{ .scalar = .bool }),
        .normalization_rule_tsv = fd(6, .{ .scalar = .string }),
    };

    /// Encodes the message to the writer
    /// The allocator is used to generate submessages internally.
    /// Hence, an ArenaAllocator is a preferred choice if allocations are a bottleneck.
    pub fn encode(
        self: @This(),
        writer: *std.Io.Writer,
        allocator: std.mem.Allocator,
    ) (std.Io.Writer.Error || std.mem.Allocator.Error)!void {
        return protobuf.encode(writer, allocator, self);
    }

    /// Decodes the message from the bytes read from the reader.
    pub fn decode(
        reader: *std.Io.Reader,
        allocator: std.mem.Allocator,
    ) (protobuf.DecodingError || std.Io.Reader.Error || std.mem.Allocator.Error)!@This() {
        return protobuf.decode(@This(), reader, allocator);
    }

    /// Deinitializes and frees the memory associated with the message.
    pub fn deinit(self: *@This(), allocator: std.mem.Allocator) void {
        return protobuf.deinit(allocator, self);
    }

    /// Duplicates the message.
    pub fn dupe(self: @This(), allocator: std.mem.Allocator) std.mem.Allocator.Error!@This() {
        return protobuf.dupe(@This(), self, allocator);
    }

    /// Decodes the message from the JSON string.
    pub fn jsonDecode(
        input: []const u8,
        options: std.json.ParseOptions,
        allocator: std.mem.Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.json.decode(@This(), input, options, allocator);
    }

    /// Encodes the message to a JSON string.
    pub fn jsonEncode(
        self: @This(),
        options: std.json.Stringify.Options,
        allocator: std.mem.Allocator,
    ) ![]const u8 {
        return protobuf.json.encode(self, options, allocator);
    }

    /// This method is used by std.json
    /// internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: std.mem.Allocator,
        source: anytype,
        options: std.json.ParseOptions,
    ) !@This() {
        return protobuf.json.parse(@This(), allocator, source, options);
    }

    /// This method is used by std.json
    /// internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.json.stringify(@This(), self, jws);
    }
};

/// Proto to store samples for self-testing.
pub const SelfTestData = struct {
    samples: std.ArrayListUnmanaged(SelfTestData.Sample) = .empty,

    pub const _desc_table = .{
        .samples = fd(1, .{ .repeated = .submessage }),
    };

    pub const Sample = struct {
        input: ?[]const u8 = null,
        expected: ?[]const u8 = null,

        pub const _desc_table = .{
            .input = fd(1, .{ .scalar = .string }),
            .expected = fd(2, .{ .scalar = .string }),
        };

        /// Encodes the message to the writer
        /// The allocator is used to generate submessages internally.
        /// Hence, an ArenaAllocator is a preferred choice if allocations are a bottleneck.
        pub fn encode(
            self: @This(),
            writer: *std.Io.Writer,
            allocator: std.mem.Allocator,
        ) (std.Io.Writer.Error || std.mem.Allocator.Error)!void {
            return protobuf.encode(writer, allocator, self);
        }

        /// Decodes the message from the bytes read from the reader.
        pub fn decode(
            reader: *std.Io.Reader,
            allocator: std.mem.Allocator,
        ) (protobuf.DecodingError || std.Io.Reader.Error || std.mem.Allocator.Error)!@This() {
            return protobuf.decode(@This(), reader, allocator);
        }

        /// Deinitializes and frees the memory associated with the message.
        pub fn deinit(self: *@This(), allocator: std.mem.Allocator) void {
            return protobuf.deinit(allocator, self);
        }

        /// Duplicates the message.
        pub fn dupe(self: @This(), allocator: std.mem.Allocator) std.mem.Allocator.Error!@This() {
            return protobuf.dupe(@This(), self, allocator);
        }

        /// Decodes the message from the JSON string.
        pub fn jsonDecode(
            input: []const u8,
            options: std.json.ParseOptions,
            allocator: std.mem.Allocator,
        ) !std.json.Parsed(@This()) {
            return protobuf.json.decode(@This(), input, options, allocator);
        }

        /// Encodes the message to a JSON string.
        pub fn jsonEncode(
            self: @This(),
            options: std.json.Stringify.Options,
            allocator: std.mem.Allocator,
        ) ![]const u8 {
            return protobuf.json.encode(self, options, allocator);
        }

        /// This method is used by std.json
        /// internally for deserialization. DO NOT RENAME!
        pub fn jsonParse(
            allocator: std.mem.Allocator,
            source: anytype,
            options: std.json.ParseOptions,
        ) !@This() {
            return protobuf.json.parse(@This(), allocator, source, options);
        }

        /// This method is used by std.json
        /// internally for serialization. DO NOT RENAME!
        pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
            return protobuf.json.stringify(@This(), self, jws);
        }
    };

    /// Encodes the message to the writer
    /// The allocator is used to generate submessages internally.
    /// Hence, an ArenaAllocator is a preferred choice if allocations are a bottleneck.
    pub fn encode(
        self: @This(),
        writer: *std.Io.Writer,
        allocator: std.mem.Allocator,
    ) (std.Io.Writer.Error || std.mem.Allocator.Error)!void {
        return protobuf.encode(writer, allocator, self);
    }

    /// Decodes the message from the bytes read from the reader.
    pub fn decode(
        reader: *std.Io.Reader,
        allocator: std.mem.Allocator,
    ) (protobuf.DecodingError || std.Io.Reader.Error || std.mem.Allocator.Error)!@This() {
        return protobuf.decode(@This(), reader, allocator);
    }

    /// Deinitializes and frees the memory associated with the message.
    pub fn deinit(self: *@This(), allocator: std.mem.Allocator) void {
        return protobuf.deinit(allocator, self);
    }

    /// Duplicates the message.
    pub fn dupe(self: @This(), allocator: std.mem.Allocator) std.mem.Allocator.Error!@This() {
        return protobuf.dupe(@This(), self, allocator);
    }

    /// Decodes the message from the JSON string.
    pub fn jsonDecode(
        input: []const u8,
        options: std.json.ParseOptions,
        allocator: std.mem.Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.json.decode(@This(), input, options, allocator);
    }

    /// Encodes the message to a JSON string.
    pub fn jsonEncode(
        self: @This(),
        options: std.json.Stringify.Options,
        allocator: std.mem.Allocator,
    ) ![]const u8 {
        return protobuf.json.encode(self, options, allocator);
    }

    /// This method is used by std.json
    /// internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: std.mem.Allocator,
        source: anytype,
        options: std.json.ParseOptions,
    ) !@This() {
        return protobuf.json.parse(@This(), allocator, source, options);
    }

    /// This method is used by std.json
    /// internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.json.stringify(@This(), self, jws);
    }
};

/// ModelProto stores model parameters.
/// SentencePieceProcessor is supposed to be self-contained.
/// All settings/parameters which may change the behavior must be encoded
/// in ModelProto.
pub const ModelProto = struct {
    pieces: std.ArrayListUnmanaged(ModelProto.SentencePiece) = .empty,
    trainer_spec: ?TrainerSpec = null,
    normalizer_spec: ?NormalizerSpec = null,
    self_test_data: ?SelfTestData = null,
    denormalizer_spec: ?NormalizerSpec = null,

    pub const _desc_table = .{
        .pieces = fd(1, .{ .repeated = .submessage }),
        .trainer_spec = fd(2, .submessage),
        .normalizer_spec = fd(3, .submessage),
        .self_test_data = fd(4, .submessage),
        .denormalizer_spec = fd(5, .submessage),
    };

    pub const SentencePiece = struct {
        piece: ?[]const u8 = null,
        score: ?f32 = null,
        type: ?ModelProto.SentencePiece.Type = .NORMAL,

        pub const _desc_table = .{
            .piece = fd(1, .{ .scalar = .string }),
            .score = fd(2, .{ .scalar = .float }),
            .type = fd(3, .@"enum"),
        };

        pub const Type = enum(i32) {
            NORMAL = 1,
            UNKNOWN = 2,
            CONTROL = 3,
            USER_DEFINED = 4,
            BYTE = 6,
            UNUSED = 5,
            _,
        };

        /// Encodes the message to the writer
        /// The allocator is used to generate submessages internally.
        /// Hence, an ArenaAllocator is a preferred choice if allocations are a bottleneck.
        pub fn encode(
            self: @This(),
            writer: *std.Io.Writer,
            allocator: std.mem.Allocator,
        ) (std.Io.Writer.Error || std.mem.Allocator.Error)!void {
            return protobuf.encode(writer, allocator, self);
        }

        /// Decodes the message from the bytes read from the reader.
        pub fn decode(
            reader: *std.Io.Reader,
            allocator: std.mem.Allocator,
        ) (protobuf.DecodingError || std.Io.Reader.Error || std.mem.Allocator.Error)!@This() {
            return protobuf.decode(@This(), reader, allocator);
        }

        /// Deinitializes and frees the memory associated with the message.
        pub fn deinit(self: *@This(), allocator: std.mem.Allocator) void {
            return protobuf.deinit(allocator, self);
        }

        /// Duplicates the message.
        pub fn dupe(self: @This(), allocator: std.mem.Allocator) std.mem.Allocator.Error!@This() {
            return protobuf.dupe(@This(), self, allocator);
        }

        /// Decodes the message from the JSON string.
        pub fn jsonDecode(
            input: []const u8,
            options: std.json.ParseOptions,
            allocator: std.mem.Allocator,
        ) !std.json.Parsed(@This()) {
            return protobuf.json.decode(@This(), input, options, allocator);
        }

        /// Encodes the message to a JSON string.
        pub fn jsonEncode(
            self: @This(),
            options: std.json.Stringify.Options,
            allocator: std.mem.Allocator,
        ) ![]const u8 {
            return protobuf.json.encode(self, options, allocator);
        }

        /// This method is used by std.json
        /// internally for deserialization. DO NOT RENAME!
        pub fn jsonParse(
            allocator: std.mem.Allocator,
            source: anytype,
            options: std.json.ParseOptions,
        ) !@This() {
            return protobuf.json.parse(@This(), allocator, source, options);
        }

        /// This method is used by std.json
        /// internally for serialization. DO NOT RENAME!
        pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
            return protobuf.json.stringify(@This(), self, jws);
        }
    };

    /// Encodes the message to the writer
    /// The allocator is used to generate submessages internally.
    /// Hence, an ArenaAllocator is a preferred choice if allocations are a bottleneck.
    pub fn encode(
        self: @This(),
        writer: *std.Io.Writer,
        allocator: std.mem.Allocator,
    ) (std.Io.Writer.Error || std.mem.Allocator.Error)!void {
        return protobuf.encode(writer, allocator, self);
    }

    /// Decodes the message from the bytes read from the reader.
    pub fn decode(
        reader: *std.Io.Reader,
        allocator: std.mem.Allocator,
    ) (protobuf.DecodingError || std.Io.Reader.Error || std.mem.Allocator.Error)!@This() {
        return protobuf.decode(@This(), reader, allocator);
    }

    /// Deinitializes and frees the memory associated with the message.
    pub fn deinit(self: *@This(), allocator: std.mem.Allocator) void {
        return protobuf.deinit(allocator, self);
    }

    /// Duplicates the message.
    pub fn dupe(self: @This(), allocator: std.mem.Allocator) std.mem.Allocator.Error!@This() {
        return protobuf.dupe(@This(), self, allocator);
    }

    /// Decodes the message from the JSON string.
    pub fn jsonDecode(
        input: []const u8,
        options: std.json.ParseOptions,
        allocator: std.mem.Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.json.decode(@This(), input, options, allocator);
    }

    /// Encodes the message to a JSON string.
    pub fn jsonEncode(
        self: @This(),
        options: std.json.Stringify.Options,
        allocator: std.mem.Allocator,
    ) ![]const u8 {
        return protobuf.json.encode(self, options, allocator);
    }

    /// This method is used by std.json
    /// internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: std.mem.Allocator,
        source: anytype,
        options: std.json.ParseOptions,
    ) !@This() {
        return protobuf.json.parse(@This(), allocator, source, options);
    }

    /// This method is used by std.json
    /// internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.json.stringify(@This(), self, jws);
    }
};
